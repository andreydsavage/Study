{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучим модели для классификации отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import json \n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from functions.util_func import data_preprocessing, encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['part', 'movie_name', 'review_id', 'author', 'date', 'title', 'grade3',\n",
      "       'grade10', 'content'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Загружаем датасет и выбиарем колнки с отзывом и оценкой\n",
    "df = pd.read_json('../kinopoisk.jsonl', lines=True)\n",
    "print(df.columns)\n",
    "df = df[['grade3', 'content']]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade3</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>\\n\"Блеф» — одна из моих самых любимых комедий....</td>\n",
       "      <td>2</td>\n",
       "      <td>блеф» — одн мо сам любим комед фильм наверн см...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>\\nАдриано Челентано продолжает радовать нас св...</td>\n",
       "      <td>2</td>\n",
       "      <td>адриа челента продолжа радова сво работ жизн к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>\\nНесомненно, это один из великих фильмов 80-х...</td>\n",
       "      <td>2</td>\n",
       "      <td>несомнен эт велик фильм 80х год исключительн к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>\\nЭта фраза на мой взгляд отражает сюжет несом...</td>\n",
       "      <td>2</td>\n",
       "      <td>эт фраз взгляд отража сюжет несомнен прекрасн ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>\\n- как пела Земфира, скорее всего, по соверше...</td>\n",
       "      <td>1</td>\n",
       "      <td>пел земфир скор совершен друг повод «фильм чел...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    grade3                                            content  label  \\\n",
       "0     Good  \\n\"Блеф» — одна из моих самых любимых комедий....      2   \n",
       "1     Good  \\nАдриано Челентано продолжает радовать нас св...      2   \n",
       "2     Good  \\nНесомненно, это один из великих фильмов 80-х...      2   \n",
       "3     Good  \\nЭта фраза на мой взгляд отражает сюжет несом...      2   \n",
       "4  Neutral  \\n- как пела Земфира, скорее всего, по соверше...      1   \n",
       "\n",
       "                                     cleaned_content  \n",
       "0  блеф» — одн мо сам любим комед фильм наверн см...  \n",
       "1  адриа челента продолжа радова сво работ жизн к...  \n",
       "2  несомнен эт велик фильм 80х год исключительн к...  \n",
       "3  эт фраз взгляд отража сюжет несомнен прекрасн ...  \n",
       "4  пел земфир скор совершен друг повод «фильм чел...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Преобработка текста для bag of words and RNN models\n",
    "df[\"cleaned_content\"] = df[\"content\"].apply(data_preprocessing)\n",
    "# Encode label\n",
    "df['label'] = df[\"grade3\"].apply(encode)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF and Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36591, 24712)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.8,# Игнорируем слова которые встречаются в 80% текстов\n",
    "    min_df=10 # Игонорируем слова, которые встречаются меньше 10 раз\n",
    "    )\n",
    "vectorizer = vectorizer.fit(df.cleaned_content)\n",
    "X = vectorizer.transform(df.cleaned_content)\n",
    "\n",
    "# Сохраним vectorizer\n",
    "joblib.dump(vectorizer, \"vectorizer_tfidf.pkl\")\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8058844962652578\n",
      "f1: 0.5381581948150086\n"
     ]
    }
   ],
   "source": [
    "# Строим модель без балансировки класов\n",
    "\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['label'], test_size=0.3)\n",
    "\n",
    "# Обучение классификатора\n",
    "classifier = MultinomialNB(alpha=0.01)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Оценка классификатора\n",
    "predictions = classifier.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"f1:\", f1_score(y_test, predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7746401894698488\n",
      "f1: 0.41384797020605335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({2: 10572, 0: 381, 1: 25})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Модель с балансировкой\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Получение весов классов\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "# Создание модели с взвешиванием классов\n",
    "model = RandomForestClassifier(class_weight=dict(enumerate(class_weights)))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Оценка классификатора\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"f1:\", f1_score(y_test, predictions, average='macro'))\n",
    "# f1_sc = f1_score(y_test, predictions, average='macro')\n",
    "Counter(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7724539989069047\n",
      "f1: 0.6040766241019483\n",
      "Counter({2: 7709, 0: 1975, 1: 1294})\n"
     ]
    }
   ],
   "source": [
    "# Модель с уменьшением преобладающего класса\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Создание экземпляра RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "# Применение уменьшения выборки к данным\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Обучение классификатора\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Оценка классификатора\n",
    "predictions = classifier.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"f1:\", f1_score(y_test, predictions, average='macro'))\n",
    "print(Counter(predictions))\n",
    "\n",
    "f1_sc = f1_score(y_test, predictions, average='macro')\n",
    "\n",
    "# Save model\n",
    "joblib.dump(classifier, 'MultinomialNB.pkl')\n",
    "\n",
    "# Save f1-score\n",
    "# scores = {}\n",
    "\n",
    "with open('models_f1_scores.json', 'r') as f:\n",
    "    scores = json.load(f)\n",
    "\n",
    "with open('models_f1_scores.json', 'w') as f:\n",
    "    scores['TF-IDF'] = f1_sc\n",
    "    json.dump(scores,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7724539989069047\n",
      "f1: 0.6040766241019483\n",
      "Counter({2: 7709, 0: 1975, 1: 1294})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_resampled, y_resampled)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"f1:\", f1_score(y_test, predictions, average='macro'))\n",
    "print(Counter(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Как же уныло… Я вынужден констатировать, что славная студия Дисней утратила моё доверие и попала в чёрный список студий, новые мультфильмы которых теперь я смотреть не буду. Признаться, в списке до этого были лишь ДримВоркс, но если учесть, что для меня в анимации существует только три крупных рыбы — Дисней, ДримВоркс и Пиксар, то надежда остаётся только на последних. Те, слава Богу, в последние годы делают исключительно шедевры или близко к ним, так что можно не беспокоиться. \n",
      "\n",
      "Ближе к «Рапунцель». Во время просмотра у меня постоянно копились новые претензии, которые я впоследствии забывал по причине их обильности. Поэтому я пойду проверенной схемой, поочередно обозвав плохими словами сюжет, юмор и персонажей. Начнём.\n",
      "\n",
      "I. Сюжет.\n",
      "\n",
      "Герои движутся из точки А в точку Б, попутно зарабатывая приключения на свою пятую точку. У меня сразу возникает дежавю, потому что тоже самое я писал в своём отзыве на «Ледниковый период». Ну мультфильмов с такой концепцией — миллионы. Другое дело, что я такие мультики не люблю. Единственный плюс, который я нашёл — нет говорящих животных. Ну и обязательная любовная линия. Как же без этого. Всё по законам тупых, банальных фильмов. Про это писать не буду, ибо и так понятно.\n",
      "\n",
      "Чем заканчивается мультик, понятно тоже. Вроде бы неожиданные сюжетные твисты порой оборачиваются таким абсурдом…\n",
      "\n",
      "PS. В одной рецензии прочитал, что сюжет в мультфильме гениальный. Жуть.\n",
      "\n",
      "II. Персонажи.\n",
      "\n",
      "С ними вообще беда. Главный мужик (тот, что вор) карикатурен до жути — самодовольный, конечно, красавчик, но внутри он лапочка. Рапунцель — тоже красотка, как и подобает, и характер замечательный — сказка же, поэтому хорошие персонажи должны быть просто феноменально хорошими. Конь напоминает осла из Шрека, только лучше — молчит всё время. Стражники, естественно, тупые, а мачеха умная, но очень злая. Штамп на штампе, поэтому и скучно. \n",
      "\n",
      "III. Юмор.\n",
      "\n",
      "А вот и самая в пух и прах разносимая мною категория. Приступаю к разгрому со зловещим смехом.\n",
      "\n",
      "Одна из главных проблем современных мультфильмов — это то, что их всех шлифуют под целевую аудиторию, то есть под детсад и началку. Ни одной более менее нормальной шутки я вспомнить не могу, потому что весь юмор заключается в ударах сковородкой по голове и тому подобные вещи. Я искренне не понимаю, почему это так смешно. Мультипликаторам давно пора прекратить вставлять такие вещи в мультфильмы, ведь это развивает жестокость в детях! Сейчас под понятием «кино для всей семьи» понимаются комедии вроде «Один дома» с пытками, в прямом смысле слова. Я уверен, что боссы студий это прекрасно понимают, но им нужны лишь деньги. По-настоящему добрые мультфильмы не начнут делать до тех пор, пока есть спрос на такие поделки. Очевидно, что спрос на такую продукцию будет всегда, поэтому ничего поделать уже нельзя. Я расстроен. Мне противно слышать, как после ударов по голове чугунной сковородой зал взрывается от детского смеха.\n",
      "\n",
      "Заканчиваю разгром с грустными мыслями. Я ненавижу мультфильм «Том и Джерри».\n",
      "\n",
      "Бонус:\n",
      "\n",
      "IV. Мъюзикальная составляющая.\n",
      "\n",
      "Мне абсолютно наплевать, какое качество у песен, а всё потому, что я не переношу этот жанр. Помню, как в своей рецензии на «Король лев» я ругал Дисней за лишнюю трату экранного времени. А ругать жанр следует не только за это. Вот представьте ситуацию: заходите вы в автобус, передаёте деньги за проезд, после чего кондуктор нараспев говорит «Спасибо»; вы, также напевая, отвечаете «Пожалуйста», и все пассажиры начинают танцевать и петь. Абсурд? Абсурд. Поэтому я и не люблю мюзиклы. \n",
      "\n",
      "Ну а для любителей — песни вроде хорошие, качественные. Правда, весь смысл, наверное, теряется при переводе, так что при возможности смотрите в оригинале с субтитрами.\n",
      "\n",
      "Вот и всё. Если можно, подведу итоги года. \n",
      "\n",
      "История игрушек 3 — 9,5 из 10.\n",
      "\n",
      "Легенды ночных стражей — 5,5 из 10.\n",
      "\n",
      "Как приручить дракона — 4 из 10.\n",
      "\n",
      "Запутанная история — 4 из 10\n",
      "\n",
      "Пиксар, как обычно, лучшие, а Дисней — неожиданно также плохи, как и Дримы. \n",
      "\n",
      "Не ходите на этот мультик.\n",
      "**********\n",
      "Клаccификация отзыва:  ('Bad', 0.02)\n"
     ]
    }
   ],
   "source": [
    "# Проверим модель\n",
    "from functions.util_func import predict\n",
    "\n",
    "vect = joblib.load(\"vectorizer_tfidf.pkl\")\n",
    "clf = joblib.load(\"MultinomialNB.pkl\")\n",
    "\n",
    "\n",
    "text = df.query('label == 0')['content'].values[0]\n",
    "print(text)\n",
    "print('*'*10)\n",
    "print(f'Клаccификация отзыва: ', predict(text, vectorizer=vect, classifier=clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим токены\n",
    "# Обычно при токенизации и сопоставлении целых чисел словам принцип такой: наиболее популярным словам соответсвуют меньшие индексы (но ноль зарезервирован – `pad`)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "corpus = [word for text in df['cleaned_content'] for word in text.split()]\n",
    "count_words = Counter(corpus)\n",
    "# print(count_words)\n",
    "sorted_words = count_words.most_common()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Можем взять только слова, которые чаще всего встречаются в данных, \n",
    "# но это гиперпараметр\n",
    "def get_words_by_freq(sorted_words: list, n: int = 10) -> list:\n",
    "    return list(filter(lambda x: x[1] > n, sorted_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('таганрог', 11),\n",
       " ('слепак', 11),\n",
       " ('скетчком', 11),\n",
       " ('денисовн', 11),\n",
       " ('«беременного»', 11),\n",
       " ('шплинт', 11),\n",
       " ('юнгвальдахилькевич', 11),\n",
       " ('ширвиндт', 11),\n",
       " ('gps', 11),\n",
       " ('навигатор', 11)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_words = get_words_by_freq(sorted_words, 10)\n",
    "sorted_words[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Каждому слову сопоставим целое число для дальнейшей передачи в нейросеть\n",
    "vocab_to_int = {w: i+1 for i, (w,c) in enumerate(sorted_words)}\n",
    "# save vocab\n",
    "with open(\"vocab_for_GRU.json\", \"w\") as outfile: \n",
    "    json.dump(vocab_to_int, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'фильм': 1,\n",
       " '—': 2,\n",
       " 'эт': 3,\n",
       " 'котор': 4,\n",
       " 'сво': 5,\n",
       " 'сам': 6,\n",
       " 'очен': 7,\n",
       " '10': 8,\n",
       " 'прост': 9,\n",
       " 'так': 10,\n",
       " 'жизн': 11,\n",
       " 'одн': 12,\n",
       " 'актер': 13,\n",
       " 'друг': 14,\n",
       " 'главн': 15,\n",
       " 'человек': 16,\n",
       " 'люд': 17,\n",
       " 'кажд': 18,\n",
       " 'рол': 19,\n",
       " 'картин': 20,\n",
       " 'все': 21,\n",
       " 'перв': 22,\n",
       " 'геро': 23,\n",
       " 'сюжет': 24,\n",
       " 'истор': 25,\n",
       " 'кин': 26,\n",
       " 'игр': 27,\n",
       " 'врем': 28,\n",
       " 'просмотр': 29,\n",
       " 'мир': 30,\n",
       " 'сказа': 31,\n",
       " 'говор': 32,\n",
       " 'имен': 33,\n",
       " 'зрител': 34,\n",
       " 'лучш': 35,\n",
       " 'режиссер': 36,\n",
       " 'хорош': 37,\n",
       " 'персонаж': 38,\n",
       " 'хот': 39,\n",
       " 'всем': 40,\n",
       " 'част': 41,\n",
       " 'получ': 42,\n",
       " 'люб': 43,\n",
       " 'сто': 44,\n",
       " 'наш': 45,\n",
       " 'момент': 46,\n",
       " 'сдела': 47,\n",
       " 'мног': 48,\n",
       " 'лиш': 49,\n",
       " 'слов': 50,\n",
       " 'дел': 51,\n",
       " 'интересн': 52,\n",
       " 'работ': 53,\n",
       " 'нов': 54,\n",
       " 'больш': 55,\n",
       " 'смотрет': 56,\n",
       " 'нужн': 57,\n",
       " 'сцен': 58,\n",
       " 'мо': 59,\n",
       " 'показа': 60,\n",
       " 'конц': 61,\n",
       " 'нам': 62,\n",
       " 'дума': 63,\n",
       " 'стал': 64,\n",
       " 'мест': 65,\n",
       " 'чувств': 66,\n",
       " 'сыгра': 67,\n",
       " 'год': 68,\n",
       " 'хочет': 69,\n",
       " 'смотр': 70,\n",
       " 'понрав': 71,\n",
       " 'вообщ': 72,\n",
       " 'образ': 73,\n",
       " 'настоя': 74,\n",
       " 'мог': 75,\n",
       " 'отличн': 76,\n",
       " 'действительн': 77,\n",
       " 'сильн': 78,\n",
       " 'прекрасн': 79,\n",
       " 'дела': 80,\n",
       " 'музык': 81,\n",
       " 'гер': 82,\n",
       " 'душ': 83,\n",
       " 'ещ': 84,\n",
       " 'оста': 85,\n",
       " 'цел': 86,\n",
       " 'игра': 87,\n",
       " 'актерск': 88,\n",
       " 'вид': 89,\n",
       " 'дан': 90,\n",
       " 'добр': 91,\n",
       " 'взгляд': 92,\n",
       " 'возможн': 93,\n",
       " 'глаз': 94,\n",
       " 'нача': 95,\n",
       " 'посмотрет': 96,\n",
       " 'втор': 97,\n",
       " 'нем': 98,\n",
       " 'любов': 99,\n",
       " 'явля': 100,\n",
       " 'поня': 101,\n",
       " 'е': 102,\n",
       " 'хотел': 103,\n",
       " 'понима': 104,\n",
       " 'великолепн': 105,\n",
       " 'чтот': 106,\n",
       " 'особен': 107,\n",
       " 'смысл': 108,\n",
       " 'последн': 109,\n",
       " 'времен': 110,\n",
       " 'лет': 111,\n",
       " 'красив': 112,\n",
       " 'вер': 113,\n",
       " 'созда': 114,\n",
       " 'общ': 115,\n",
       " 'сторон': 116,\n",
       " 'шедевр': 117,\n",
       " 'никак': 118,\n",
       " 'начина': 119,\n",
       " 'как': 120,\n",
       " 'мультфильм': 121,\n",
       " 'рад': 122,\n",
       " 'такж': 123,\n",
       " 'настольк': 124,\n",
       " 'снят': 125,\n",
       " 'любим': 126,\n",
       " 'минут': 127,\n",
       " 'совершен': 128,\n",
       " 'ве': 129,\n",
       " 'поэт': 130,\n",
       " 'сценар': 131,\n",
       " 'эмоц': 132,\n",
       " 'счита': 133,\n",
       " 'действ': 134,\n",
       " 'смотрел': 135,\n",
       " 'книг': 136,\n",
       " 'впечатлен': 137,\n",
       " 'нескольк': 138,\n",
       " 'кажет': 139,\n",
       " 'некотор': 140,\n",
       " 'лиц': 141,\n",
       " 'плох': 142,\n",
       " 'стран': 143,\n",
       " 'атмосфер': 144,\n",
       " 'мысл': 145,\n",
       " 'вмест': 146,\n",
       " 'сраз': 147,\n",
       " 'должн': 148,\n",
       " 'любв': 149,\n",
       " 'вопрос': 150,\n",
       " 'снима': 151,\n",
       " 'юмор': 152,\n",
       " 'дет': 153,\n",
       " 'полн': 154,\n",
       " 'поч': 155,\n",
       " 'видел': 156,\n",
       " 'холмс': 157,\n",
       " 'жанр': 158,\n",
       " 'замечательн': 159,\n",
       " 'станов': 160,\n",
       " 'гениальн': 161,\n",
       " 'буд': 162,\n",
       " 'пор': 163,\n",
       " 'кинематограф': 164,\n",
       " 'тем': 165,\n",
       " 'сил': 166,\n",
       " 'точн': 167,\n",
       " 'случа': 168,\n",
       " 'наверн': 169,\n",
       " 'немн': 170,\n",
       " 'собствен': 171,\n",
       " 'абсолютн': 172,\n",
       " 'итог': 173,\n",
       " 'обычн': 174,\n",
       " 'мал': 175,\n",
       " 'событ': 176,\n",
       " 'зна': 177,\n",
       " 'голов': 178,\n",
       " 'заставля': 179,\n",
       " 'сложн': 180,\n",
       " 'подобн': 181,\n",
       " 'пыта': 182,\n",
       " 'остальн': 183,\n",
       " 'долг': 184,\n",
       " 'тех': 185,\n",
       " 'войн': 186,\n",
       " 'слишк': 187,\n",
       " 'экран': 188,\n",
       " 'сердц': 189,\n",
       " 'важн': 190,\n",
       " 'реш': 191,\n",
       " 'сем': 192,\n",
       " 'вниман': 193,\n",
       " 'час': 194,\n",
       " 'единствен': 195,\n",
       " 'личн': 196,\n",
       " 'довольн': 197,\n",
       " 'огромн': 198,\n",
       " 'том': 199,\n",
       " 'однак': 200,\n",
       " 'ярк': 201,\n",
       " 'маленьк': 202,\n",
       " 'пуст': 203,\n",
       " 'велик': 204,\n",
       " 'разн': 205,\n",
       " 'показыва': 206,\n",
       " 'правд': 207,\n",
       " 'реальн': 208,\n",
       " 'смешн': 209,\n",
       " 'приятн': 210,\n",
       " 'отношен': 211,\n",
       " 'спецэффект': 212,\n",
       " 'оказа': 213,\n",
       " 'нола': 214,\n",
       " 'особ': 215,\n",
       " 'рук': 216,\n",
       " 'потряса': 217,\n",
       " 'вызыва': 218,\n",
       " 'ид': 219,\n",
       " 'те': 220,\n",
       " 'создател': 221,\n",
       " 'уда': 222,\n",
       " 'похож': 223,\n",
       " 'кадр': 224,\n",
       " 'посмотрел': 225,\n",
       " 'изз': 226,\n",
       " 'план': 227,\n",
       " 'сказк': 228,\n",
       " 'дом': 229,\n",
       " 'девушк': 230,\n",
       " 'честн': 231,\n",
       " 'современ': 232,\n",
       " 'комед': 233,\n",
       " 'несмотр': 234,\n",
       " 'прав': 235,\n",
       " 'отдельн': 236,\n",
       " 'след': 237,\n",
       " 'скаж': 238,\n",
       " 'всетак': 239,\n",
       " 'давн': 240,\n",
       " 'невозможн': 241,\n",
       " 'известн': 242,\n",
       " 'молод': 243,\n",
       " 'прошл': 244,\n",
       " 'мнен': 245,\n",
       " 'драм': 246,\n",
       " 'легк': 247,\n",
       " 'оценк': 248,\n",
       " 'джон': 249,\n",
       " 'лент': 250,\n",
       " 'пут': 251,\n",
       " 'смерт': 252,\n",
       " 'невероятн': 253,\n",
       " 'жив': 254,\n",
       " 'снов': 255,\n",
       " 'жит': 256,\n",
       " 'отмет': 257,\n",
       " 'происход': 258,\n",
       " 'выход': 259,\n",
       " 'страшн': 260,\n",
       " 'искрен': 261,\n",
       " 'соб': 262,\n",
       " 'желан': 263,\n",
       " 'американск': 264,\n",
       " 'мен': 265,\n",
       " 'скор': 266,\n",
       " 'переда': 267,\n",
       " 'ден': 268,\n",
       " 'человеческ': 269,\n",
       " 'жесток': 270,\n",
       " 'долж': 271,\n",
       " 'судьб': 272,\n",
       " 'знает': 273,\n",
       " 'наход': 274,\n",
       " 'т': 275,\n",
       " 'иде': 276,\n",
       " 'ощущен': 277,\n",
       " 'никт': 278,\n",
       " 'получа': 279,\n",
       " 'посмотр': 280,\n",
       " 'слез': 281,\n",
       " 'практическ': 282,\n",
       " 'увидет': 283,\n",
       " 'уровн': 284,\n",
       " 'глубок': 285,\n",
       " 'двух': 286,\n",
       " 'ход': 287,\n",
       " 'могл': 288,\n",
       " 'врод': 289,\n",
       " 'друз': 290,\n",
       " 'он': 291,\n",
       " 'понятн': 292,\n",
       " 'очередн': 293,\n",
       " 'женщин': 294,\n",
       " 'проблем': 295,\n",
       " 'приход': 296,\n",
       " 'стар': 297,\n",
       " 'кром': 298,\n",
       " '9': 299,\n",
       " 'неплох': 300,\n",
       " 'нрав': 301,\n",
       " 'диалог': 302,\n",
       " 'вполн': 303,\n",
       " 'вещ': 304,\n",
       " 'достойн': 305,\n",
       " 'идеальн': 306,\n",
       " 'равн': 307,\n",
       " 'далек': 308,\n",
       " 'город': 309,\n",
       " 'ожида': 310,\n",
       " 'достаточн': 311,\n",
       " 'экра': 312,\n",
       " 'способн': 313,\n",
       " 'назва': 314,\n",
       " 'каза': 315,\n",
       " 'героин': 316,\n",
       " 'спасиб': 317,\n",
       " 'измен': 318,\n",
       " 'реальност': 319,\n",
       " 'могут': 320,\n",
       " 'благодар': 321,\n",
       " 'жен': 322,\n",
       " 'написа': 323,\n",
       " 'им': 324,\n",
       " 'характер': 325,\n",
       " 'узна': 326,\n",
       " 'полност': 327,\n",
       " 'счаст': 328,\n",
       " 'ситуац': 329,\n",
       " 'оригинальн': 330,\n",
       " 'пар': 331,\n",
       " 'плюс': 332,\n",
       " 'остав': 333,\n",
       " '2': 334,\n",
       " 'весьм': 335,\n",
       " 'скольк': 336,\n",
       " 'пок': 337,\n",
       " 'стольк': 338,\n",
       " 'хоч': 339,\n",
       " 'качеств': 340,\n",
       " 'шерлок': 341,\n",
       " 'брат': 342,\n",
       " 'фраз': 343,\n",
       " 'удивительн': 344,\n",
       " 'исполнен': 345,\n",
       " 'протяжен': 346,\n",
       " 'происходя': 347,\n",
       " 'истин': 348,\n",
       " 'русск': 349,\n",
       " 'серьезн': 350,\n",
       " 'эпизод': 351,\n",
       " 'основн': 352,\n",
       " 'тяжел': 353,\n",
       " 'лин': 354,\n",
       " 'оскар': 355,\n",
       " 'реценз': 356,\n",
       " 'интерес': 357,\n",
       " 'надежд': 358,\n",
       " 'смог': 359,\n",
       " 'ответ': 360,\n",
       " 'увидел': 361,\n",
       " 'застав': 362,\n",
       " 'чем': 363,\n",
       " 'безусловн': 364,\n",
       " 'постоя': 365,\n",
       " 'свет': 366,\n",
       " 'кстат': 367,\n",
       " 'обязательн': 368,\n",
       " 'детств': 369,\n",
       " 'мер': 370,\n",
       " 'назван': 371,\n",
       " 'произведен': 372,\n",
       " 'будущ': 373,\n",
       " 'мечт': 374,\n",
       " 'пожал': 375,\n",
       " 'сут': 376,\n",
       " 'ряд': 377,\n",
       " 'какт': 378,\n",
       " 'ктот': 379,\n",
       " 'стол': 380,\n",
       " 'задума': 381,\n",
       " 'деньг': 382,\n",
       " 'справ': 383,\n",
       " 'например': 384,\n",
       " 'талант': 385,\n",
       " 'ум': 386,\n",
       " 'пример': 387,\n",
       " 'бо': 388,\n",
       " 'имеет': 389,\n",
       " 'роберт': 390,\n",
       " 'сценарист': 391,\n",
       " 'называ': 392,\n",
       " 'трудн': 393,\n",
       " 'положительн': 394,\n",
       " 'выгляд': 395,\n",
       " 'правильн': 396,\n",
       " 'помн': 397,\n",
       " 'отц': 398,\n",
       " 'рич': 399,\n",
       " 'призна': 400,\n",
       " 'кристофер': 401,\n",
       " 'дал': 402,\n",
       " 'потеря': 403,\n",
       " 'всяк': 404,\n",
       " 'сын': 405,\n",
       " 'количеств': 406,\n",
       " 'захватыва': 407,\n",
       " 'идет': 408,\n",
       " 'джокер': 409,\n",
       " 'будут': 410,\n",
       " 'быва': 411,\n",
       " 'мил': 412,\n",
       " 'кинотеатр': 413,\n",
       " 'собак': 414,\n",
       " 'чита': 415,\n",
       " 'сюжетн': 416,\n",
       " 'прич': 417,\n",
       " 'найт': 418,\n",
       " 'зат': 419,\n",
       " 'ник': 420,\n",
       " 'дух': 421,\n",
       " 'чист': 422,\n",
       " 'трет': 423,\n",
       " 'стат': 424,\n",
       " 'определен': 425,\n",
       " 'трогательн': 426,\n",
       " 'верн': 427,\n",
       " 'концовк': 428,\n",
       " 'удовольств': 429,\n",
       " 'жал': 430,\n",
       " 'вся': 431,\n",
       " 'глуп': 432,\n",
       " 'либ': 433,\n",
       " 'дальш': 434,\n",
       " 'любл': 435,\n",
       " 'существ': 436,\n",
       " 'джек': 437,\n",
       " 'высок': 438,\n",
       " 'ужас': 439,\n",
       " 'качествен': 440,\n",
       " 'саундтрек': 441,\n",
       " 'заслужива': 442,\n",
       " 'творен': 443,\n",
       " 'начал': 444,\n",
       " 'шутк': 445,\n",
       " 'страх': 446,\n",
       " 'обществ': 447,\n",
       " 'явн': 448,\n",
       " 'автор': 449,\n",
       " '1': 450,\n",
       " 'талантлив': 451,\n",
       " 'представля': 452,\n",
       " 'дружб': 453,\n",
       " 'заб': 454,\n",
       " 'фон': 455,\n",
       " 'га': 456,\n",
       " 'ког': 457,\n",
       " 'принцип': 458,\n",
       " 'век': 459,\n",
       " 'крайн': 460,\n",
       " 'ужасн': 461,\n",
       " 'необычн': 462,\n",
       " 'знаком': 463,\n",
       " 'конец': 464,\n",
       " 'проч': 465,\n",
       " 'экранизац': 466,\n",
       " 'ко': 467,\n",
       " 'боевик': 468,\n",
       " 'свобод': 469,\n",
       " 'какойт': 470,\n",
       " 'присутств': 471,\n",
       " 'детск': 472,\n",
       " 'большинств': 473,\n",
       " 'теб': 474,\n",
       " 'знач': 475,\n",
       " 'дает': 476,\n",
       " '3': 477,\n",
       " 'писа': 478,\n",
       " 'вечн': 479,\n",
       " 'успех': 480,\n",
       " 'весел': 481,\n",
       " 'напряжен': 482,\n",
       " 'дорог': 483,\n",
       " 'актрис': 484,\n",
       " 'способ': 485,\n",
       " 'постав': 486,\n",
       " 'наблюда': 487,\n",
       " 'рассказыва': 488,\n",
       " 'иб': 489,\n",
       " 'взросл': 490,\n",
       " 'меня': 491,\n",
       " 'факт': 492,\n",
       " 'триллер': 493,\n",
       " 'сред': 494,\n",
       " 'раз': 495,\n",
       " 'сожален': 496,\n",
       " 'род': 497,\n",
       " 'работа': 498,\n",
       " '8': 499,\n",
       " 'оказыва': 500,\n",
       " 'мальчик': 501,\n",
       " 'порадова': 502,\n",
       " 'снял': 503,\n",
       " 'цен': 504,\n",
       " 'появля': 505,\n",
       " 'то': 506,\n",
       " 'множеств': 507,\n",
       " 'миров': 508,\n",
       " 'вспомн': 509,\n",
       " 'знал': 510,\n",
       " 'тво': 511,\n",
       " 'нек': 512,\n",
       " 'вокруг': 513,\n",
       " 'видет': 514,\n",
       " 'ин': 515,\n",
       " 'подума': 516,\n",
       " 'совет': 517,\n",
       " 'причин': 518,\n",
       " 'парод': 519,\n",
       " 'майкл': 520,\n",
       " 'близк': 521,\n",
       " 'классик': 522,\n",
       " 'удачн': 523,\n",
       " 'песн': 524,\n",
       " 'инач': 525,\n",
       " 'ваш': 526,\n",
       " 'безумн': 527,\n",
       " 'ватсон': 528,\n",
       " 'минус': 529,\n",
       " 'очеред': 530,\n",
       " 'выбор': 531,\n",
       " 'красот': 532,\n",
       " 'скучн': 533,\n",
       " 'естествен': 534,\n",
       " 'бог': 535,\n",
       " 'мужчин': 536,\n",
       " 'умн': 537,\n",
       " 'пол': 538,\n",
       " 'лишн': 539,\n",
       " 'наскольк': 540,\n",
       " 'соста': 541,\n",
       " 'пересматрива': 542,\n",
       " 'окружа': 543,\n",
       " 'стил': 544,\n",
       " 'выш': 545,\n",
       " 'готов': 546,\n",
       " 'прям': 547,\n",
       " 'помощ': 548,\n",
       " 'личност': 549,\n",
       " 'ps': 550,\n",
       " 'реч': 551,\n",
       " 'эффект': 552,\n",
       " 'картинк': 553,\n",
       " 'редк': 554,\n",
       " 'музыкальн': 555,\n",
       " 'забавн': 556,\n",
       " 'вовс': 557,\n",
       " 'черн': 558,\n",
       " 'непонятн': 559,\n",
       " 'бол': 560,\n",
       " 'ком': 561,\n",
       " 'ждал': 562,\n",
       " 'та': 563,\n",
       " 'настроен': 564,\n",
       " 'отсутств': 565,\n",
       " 'меньш': 566,\n",
       " 'приключен': 567,\n",
       " 'половин': 568,\n",
       " 'неожида': 569,\n",
       " 'фина': 570,\n",
       " 'счастлив': 571,\n",
       " 'парн': 572,\n",
       " 'подобра': 573,\n",
       " 'об': 574,\n",
       " 'улыбк': 575,\n",
       " 'замет': 576,\n",
       " 'черт': 577,\n",
       " 'доктор': 578,\n",
       " 'российск': 579,\n",
       " 'родител': 580,\n",
       " 'мозг': 581,\n",
       " 'повер': 582,\n",
       " 'пришл': 583,\n",
       " 'оставля': 584,\n",
       " 'видн': 585,\n",
       " 'появ': 586,\n",
       " 'прот': 587,\n",
       " 'продолжен': 588,\n",
       " 'высш': 589,\n",
       " 'жизнен': 590,\n",
       " 'хвата': 591,\n",
       " 'каса': 592,\n",
       " 'машин': 593,\n",
       " 'сер': 594,\n",
       " '5': 595,\n",
       " 'восторг': 596,\n",
       " 'запомн': 597,\n",
       " 'представ': 598,\n",
       " 'точк': 599,\n",
       " 'буквальн': 600,\n",
       " 'ран': 601,\n",
       " 'законч': 602,\n",
       " 'запомина': 603,\n",
       " 'помога': 604,\n",
       " 'мно': 605,\n",
       " 'поступк': 606,\n",
       " 'мультик': 607,\n",
       " 'раньш': 608,\n",
       " 'подход': 609,\n",
       " 'искусств': 610,\n",
       " 'глубин': 611,\n",
       " 'суд': 612,\n",
       " 'словн': 613,\n",
       " 'нечт': 614,\n",
       " 'увер': 615,\n",
       " 'став': 616,\n",
       " 'назад': 617,\n",
       " 'развит': 618,\n",
       " 'напомина': 619,\n",
       " 'отзыв': 620,\n",
       " 'народ': 621,\n",
       " 'корол': 622,\n",
       " 'реша': 623,\n",
       " 'хуж': 624,\n",
       " 'ребенк': 625,\n",
       " 'радост': 626,\n",
       " 'бесконечн': 627,\n",
       " 'уч': 628,\n",
       " 'вызва': 629,\n",
       " 'сих': 630,\n",
       " 'занима': 631,\n",
       " 'финальн': 632,\n",
       " 'относ': 633,\n",
       " 'снача': 634,\n",
       " 'увид': 635,\n",
       " 'светл': 636,\n",
       " 'видим': 637,\n",
       " 'голос': 638,\n",
       " 'крут': 639,\n",
       " 'встреча': 640,\n",
       " 'больн': 641,\n",
       " 'соглас': 642,\n",
       " 'дикапр': 643,\n",
       " 'возраст': 644,\n",
       " 'составля': 645,\n",
       " 'поража': 646,\n",
       " 'пошл': 647,\n",
       " 'земл': 648,\n",
       " 'откровен': 649,\n",
       " 'ген': 650,\n",
       " 'скорсез': 651,\n",
       " 'отлича': 652,\n",
       " 'режиссур': 653,\n",
       " 'взят': 654,\n",
       " 'советск': 655,\n",
       " 'сомнен': 656,\n",
       " 'секунд': 657,\n",
       " 'пережива': 658,\n",
       " 'забыва': 659,\n",
       " 'банальн': 660,\n",
       " 'декорац': 661,\n",
       " 'хит': 662,\n",
       " 'стара': 663,\n",
       " 'слав': 664,\n",
       " 'живет': 665,\n",
       " '«начало»': 666,\n",
       " 'две': 667,\n",
       " 'ув': 668,\n",
       " 'наоборот': 669,\n",
       " 'шикарн': 670,\n",
       " 'тонк': 671,\n",
       " 'понастоя': 672,\n",
       " 'миллион': 673,\n",
       " 'горазд': 674,\n",
       " 'продолжа': 675,\n",
       " 'ним': 676,\n",
       " 'отлич': 677,\n",
       " 'мор': 678,\n",
       " 'возника': 679,\n",
       " 'грустн': 680,\n",
       " 'здоров': 681,\n",
       " 'сон': 682,\n",
       " 'нормальн': 683,\n",
       " 'проект': 684,\n",
       " 'превосходн': 685,\n",
       " 'борьб': 686,\n",
       " 'балл': 687,\n",
       " 'вывод': 688,\n",
       " 'иствуд': 689,\n",
       " 'необходим': 690,\n",
       " 'темн': 691,\n",
       " 'случайн': 692,\n",
       " 'д': 693,\n",
       " 'ценност': 694,\n",
       " 'брав': 695,\n",
       " 'исключен': 696,\n",
       " 'режиссерск': 697,\n",
       " 'внутрен': 698,\n",
       " 'уб': 699,\n",
       " 'спокойн': 700,\n",
       " 'не': 701,\n",
       " 'чемт': 702,\n",
       " 'смогл': 703,\n",
       " 'быстр': 704,\n",
       " 'эмоциональн': 705,\n",
       " 'воспринима': 706,\n",
       " 'гдет': 707,\n",
       " 'любител': 708,\n",
       " 'интриг': 709,\n",
       " 'участ': 710,\n",
       " 'придума': 711,\n",
       " 'зря': 712,\n",
       " 'повествован': 713,\n",
       " 'мастер': 714,\n",
       " 'ожидан': 715,\n",
       " '7': 716,\n",
       " 'ясн': 717,\n",
       " 'счет': 718,\n",
       " 'смел': 719,\n",
       " 'вперв': 720,\n",
       " 'бел': 721,\n",
       " 'денег': 722,\n",
       " 'сможет': 723,\n",
       " 'попытк': 724,\n",
       " 'собра': 725,\n",
       " 'подруг': 726,\n",
       " 'уверен': 727,\n",
       " 'удив': 728,\n",
       " 'повод': 729,\n",
       " 'вышл': 730,\n",
       " 'отда': 731,\n",
       " 'бюджет': 732,\n",
       " 'случ': 733,\n",
       " 'критик': 734,\n",
       " 'одновремен': 735,\n",
       " 'теря': 736,\n",
       " 'выбра': 737,\n",
       " 'наград': 738,\n",
       " '«темн': 739,\n",
       " 'связа': 740,\n",
       " 'попа': 741,\n",
       " 'равнодушн': 742,\n",
       " 'зал': 743,\n",
       " 'ту': 744,\n",
       " 'кров': 745,\n",
       " 'сравнен': 746,\n",
       " 'прежд': 747,\n",
       " 'трилог': 748,\n",
       " 'съемк': 749,\n",
       " '4': 750,\n",
       " 'внов': 751,\n",
       " 'открыт': 752,\n",
       " 'знаменит': 753,\n",
       " 'уилл': 754,\n",
       " 'небольш': 755,\n",
       " 'исполн': 756,\n",
       " 'итак': 757,\n",
       " 'отрицательн': 758,\n",
       " 'девочк': 759,\n",
       " 'людьм': 760,\n",
       " 'туп': 761,\n",
       " 'душевн': 762,\n",
       " 'жела': 763,\n",
       " 'титр': 764,\n",
       " 'отец': 765,\n",
       " 'костюм': 766,\n",
       " 'воспоминан': 767,\n",
       " 'бэтм': 768,\n",
       " 'сознан': 769,\n",
       " 'леджер': 770,\n",
       " 'убийств': 771,\n",
       " 'числ': 772,\n",
       " 'памят': 773,\n",
       " 'предыдущ': 774,\n",
       " 'слаб': 775,\n",
       " 'вряд': 776,\n",
       " 'высот': 777,\n",
       " 'восхища': 778,\n",
       " 'реалистичн': 779,\n",
       " 'намн': 780,\n",
       " 'слыша': 781,\n",
       " 'опасн': 782,\n",
       " 'убива': 783,\n",
       " 'внутр': 784,\n",
       " 'мечта': 785,\n",
       " 'голливуд': 786,\n",
       " 'уважен': 787,\n",
       " 'команд': 788,\n",
       " 'тюрьм': 789,\n",
       " 'несомнен': 790,\n",
       " 'чегот': 791,\n",
       " 'операторск': 792,\n",
       " 'выда': 793,\n",
       " 'держ': 794,\n",
       " 'создан': 795,\n",
       " 'фантастическ': 796,\n",
       " 'задач': 797,\n",
       " 'криминальн': 798,\n",
       " 'дар': 799,\n",
       " 'побед': 800,\n",
       " 'смея': 801,\n",
       " 'родн': 802,\n",
       " 'плака': 803,\n",
       " 'вол': 804,\n",
       " 'пораз': 805,\n",
       " 'компан': 806,\n",
       " 'достоинств': 807,\n",
       " 'четк': 808,\n",
       " 'пят': 809,\n",
       " 'голливудск': 810,\n",
       " 'цвет': 811,\n",
       " 'разум': 812,\n",
       " 'навсегд': 813,\n",
       " 'стоя': 814,\n",
       " 'удивля': 815,\n",
       " 'решен': 816,\n",
       " 'результат': 817,\n",
       " 'жалк': 818,\n",
       " 'драк': 819,\n",
       " 'природ': 820,\n",
       " 'звезд': 821,\n",
       " 'взял': 822,\n",
       " 'собира': 823,\n",
       " 'оцен': 824,\n",
       " 'мелоч': 825,\n",
       " 'состоян': 826,\n",
       " 'разочарова': 827,\n",
       " 'леонард': 828,\n",
       " 'групп': 829,\n",
       " 'мрачн': 830,\n",
       " 'прочита': 831,\n",
       " 'закон': 832,\n",
       " 'сопровожден': 833,\n",
       " 'гор': 834,\n",
       " 'волшебн': 835,\n",
       " 'остр': 836,\n",
       " 'сегодн': 837,\n",
       " 'мат': 838,\n",
       " 'вспомина': 839,\n",
       " 'улиц': 840,\n",
       " 'однозначн': 841,\n",
       " 'смех': 842,\n",
       " 'таков': 843,\n",
       " 'мартин': 844,\n",
       " 'преврат': 845,\n",
       " 'откр': 846,\n",
       " 'погон': 847,\n",
       " 'полюб': 848,\n",
       " 'попада': 849,\n",
       " 'вышел': 850,\n",
       " 'ног': 851,\n",
       " 'визуальн': 852,\n",
       " 'поклонник': 853,\n",
       " 'неч': 854,\n",
       " 'осозна': 855,\n",
       " 'раскрыва': 856,\n",
       " 'переживан': 857,\n",
       " 'жил': 858,\n",
       " 'внешн': 859,\n",
       " 'язык': 860,\n",
       " 'ошибк': 861,\n",
       " 'тип': 862,\n",
       " 'испытыва': 863,\n",
       " 'зрелищн': 864,\n",
       " 'постановк': 865,\n",
       " 'справедлив': 866,\n",
       " 'детал': 867,\n",
       " 'депп': 868,\n",
       " 'парен': 869,\n",
       " 'классическ': 870,\n",
       " 'куч': 871,\n",
       " 'встрет': 872,\n",
       " 'оператор': 873,\n",
       " 'америк': 874,\n",
       " 'ал': 875,\n",
       " 'уникальн': 876,\n",
       " 'рома': 877,\n",
       " 'придет': 878,\n",
       " 'дава': 879,\n",
       " 'популярн': 880,\n",
       " 'психологическ': 881,\n",
       " 'разговор': 882,\n",
       " 'хозяин': 883,\n",
       " 'помо': 884,\n",
       " 'описа': 885,\n",
       " 'зрен': 886,\n",
       " 'вкус': 887,\n",
       " 'порядк': 888,\n",
       " 'воперв': 889,\n",
       " 'труд': 890,\n",
       " 'гот': 891,\n",
       " 'появлен': 892,\n",
       " 'позволя': 893,\n",
       " 'добав': 894,\n",
       " 'степен': 895,\n",
       " 'звук': 896,\n",
       " 'спуст': 897,\n",
       " 'какиет': 898,\n",
       " 'гран': 899,\n",
       " 'зло': 900,\n",
       " '«я': 901,\n",
       " 'вод': 902,\n",
       " 'заворажива': 903,\n",
       " 'облада': 904,\n",
       " 'наивн': 905,\n",
       " 'проход': 906,\n",
       " 'творчеств': 907,\n",
       " 'исключительн': 908,\n",
       " 'рассказа': 909,\n",
       " 'понят': 910,\n",
       " 'масс': 911,\n",
       " 'тарантин': 912,\n",
       " 'чуж': 913,\n",
       " 'слож': 914,\n",
       " 'вин': 915,\n",
       " 'затянут': 916,\n",
       " 'тепл': 917,\n",
       " 'состав': 918,\n",
       " 'жертв': 919,\n",
       " 'науч': 920,\n",
       " 'фантастик': 921,\n",
       " 'бред': 922,\n",
       " 'поколен': 923,\n",
       " 'сравнива': 924,\n",
       " 'идт': 925,\n",
       " 'доброт': 926,\n",
       " 'основ': 927,\n",
       " 'представлен': 928,\n",
       " 'чудесн': 929,\n",
       " 'дик': 930,\n",
       " 'английск': 931,\n",
       " 'фантаз': 932,\n",
       " 'однажд': 933,\n",
       " 'блестя': 934,\n",
       " 'принима': 935,\n",
       " 'камер': 936,\n",
       " 'пониман': 937,\n",
       " 'дыхан': 938,\n",
       " 'композитор': 939,\n",
       " 'уважа': 940,\n",
       " 'выдел': 941,\n",
       " 'вернут': 942,\n",
       " 'впечатл': 943,\n",
       " 'раскр': 944,\n",
       " 'график': 945,\n",
       " 'карьер': 946,\n",
       " 'сид': 947,\n",
       " 'тайн': 948,\n",
       " 'даун': 949,\n",
       " 'росс': 950,\n",
       " 'рекоменд': 951,\n",
       " 'чуд': 952,\n",
       " 'убийц': 953,\n",
       " 'ноч': 954,\n",
       " 'животн': 955,\n",
       " 'когот': 956,\n",
       " 'культов': 957,\n",
       " 'ждат': 958,\n",
       " 'доказа': 959,\n",
       " 'пробл': 960,\n",
       " 'середин': 961,\n",
       " 'компьютерн': 962,\n",
       " 'враг': 963,\n",
       " 'запута': 964,\n",
       " 'власт': 965,\n",
       " 'почемут': 966,\n",
       " 'дат': 967,\n",
       " 'станет': 968,\n",
       " 'оправда': 969,\n",
       " 'различн': 970,\n",
       " 'поведен': 971,\n",
       " 'элемент': 972,\n",
       " 'шаг': 973,\n",
       " 'динамичн': 974,\n",
       " 'подар': 975,\n",
       " 'мастерств': 976,\n",
       " 'мистер': 977,\n",
       " 'эдвард': 978,\n",
       " 'потрясающ': 979,\n",
       " 'крис': 980,\n",
       " 'трейлер': 981,\n",
       " 'слуша': 982,\n",
       " 'открыва': 983,\n",
       " 'сход': 984,\n",
       " 'впечатля': 985,\n",
       " 'матер': 986,\n",
       " 'ло': 987,\n",
       " 'ди': 988,\n",
       " '6': 989,\n",
       " 'выражен': 990,\n",
       " 'иска': 991,\n",
       " 'нелеп': 992,\n",
       " 'отечествен': 993,\n",
       " 'встреч': 994,\n",
       " 'историческ': 995,\n",
       " 'корабл': 996,\n",
       " 'заключен': 997,\n",
       " 'богат': 998,\n",
       " 'помоч': 999,\n",
       " 'останет': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d= open(\"vocab_for_GRU.json\")\n",
    "json.load(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переводим отзывы в \"числовой формат\"\n",
    "reviews_int = []\n",
    "for text in df['cleaned_content']:\n",
    "    r = [vocab_to_int[word] for word in text.split() if vocab_to_int.get(word)]\n",
    "    reviews_int.append(r)\n",
    "# reviews_int[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade3</th>\n",
       "      <th>content</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>label</th>\n",
       "      <th>Review len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>\\n\"Блеф» — одна из моих самых любимых комедий....</td>\n",
       "      <td>блеф» — одн мо сам любим комед фильм наверн см...</td>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>\\nАдриано Челентано продолжает радовать нас св...</td>\n",
       "      <td>адриа челента продолжа радова сво работ жизн к...</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>\\nНесомненно, это один из великих фильмов 80-х...</td>\n",
       "      <td>несомнен эт велик фильм 80х год исключительн к...</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>\\nЭта фраза на мой взгляд отражает сюжет несом...</td>\n",
       "      <td>эт фраз взгляд отража сюжет несомнен прекрасн ...</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>\\n- как пела Земфира, скорее всего, по соверше...</td>\n",
       "      <td>пел земфир скор совершен друг повод «фильм чел...</td>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    grade3                                            content  \\\n",
       "0     Good  \\n\"Блеф» — одна из моих самых любимых комедий....   \n",
       "1     Good  \\nАдриано Челентано продолжает радовать нас св...   \n",
       "2     Good  \\nНесомненно, это один из великих фильмов 80-х...   \n",
       "3     Good  \\nЭта фраза на мой взгляд отражает сюжет несом...   \n",
       "4  Neutral  \\n- как пела Земфира, скорее всего, по соверше...   \n",
       "\n",
       "                                     cleaned_content  label  Review len  \n",
       "0  блеф» — одн мо сам любим комед фильм наверн см...      2         207  \n",
       "1  адриа челента продолжа радова сво работ жизн к...      2         103  \n",
       "2  несомнен эт велик фильм 80х год исключительн к...      2          35  \n",
       "3  эт фраз взгляд отража сюжет несомнен прекрасн ...      2         109  \n",
       "4  пел земфир скор совершен друг повод «фильм чел...      1         203  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посчитаем количество слов в отзыве\n",
    "review_len = [len(x) for x in reviews_int]\n",
    "df['Review len'] = review_len\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    36591.000000\n",
      "mean       185.889126\n",
      "std        124.685720\n",
      "min          2.000000\n",
      "25%         99.000000\n",
      "50%        154.000000\n",
      "75%        239.000000\n",
      "max       1748.000000\n",
      "Name: Review len, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['Review len'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.util_func import padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0  7000  4792   675  1064     5    53    11    26  4706\n",
      "   555   907    54   407    52   451   345    25  2046   120   411  7149\n",
      "  8735    30    44   740   330  5661    16     4  2201  5232  6390  1831\n",
      "  7149  3052   256    85    11  5132     5   429  1138   209     1  2329\n",
      "  1324  1315   233     4   279  2936  1712    27    13  1911  9006   887\n",
      "   304    69  4769 11631    63    49   487    27   217    13   110  5448\n",
      "  1114  2021    91   170   905    20   533   887   330  1020    46   140\n",
      "   351   442   236  1463  4017   330   221    44    63   142    39  2614\n",
      "    53   517     2   280 17993     3    57   564   167  7385]\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 154\n",
    "features = padding(reviews_int, SEQ_LEN)\n",
    "print(features[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим датасеты\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features, df['label'].to_numpy(), test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensor dataset\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train).type(torch.LongTensor))\n",
    "valid_data = TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid).type(torch.LongTensor))\n",
    "\n",
    "# dataloaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size: BATCH_SIZE x SEQ_LEN torch.Size([32, 154])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,  ...,   441,   334,     8],\n",
      "        [  371,     1,    71,  ...,   589,   284,   113],\n",
      "        [    1,  1652,     7,  ...,   155,   392,    12],\n",
      "        ...,\n",
      "        [  190,    11,   418,  ...,   202, 21790,  1455],\n",
      "        [  556,   426,   143,  ...,     3,  1215,  1063],\n",
      "        [  474,   809,   947,  ...,   869, 16777,   117]])\n",
      "Sample input: \n",
      " tensor([1, 2, 2, 1, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 0,\n",
      "        2, 2, 0, 2, 0, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# посмотрим, что внутри\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)\n",
    "\n",
    "print('Sample input size: BATCH_SIZE x SEQ_LEN', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample input: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_config(vocab_size=24927, device='cuda', n_layers=1, embedding_dim=16, hidden_size=32, seq_len=154, bidirectional=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functions.util_func import RNN_config\n",
    "\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = RNN_config(\n",
    "    vocab_size=len(vocab_to_int)+1,\n",
    "    device=DEVICE,\n",
    "    n_layers=1,\n",
    "    embedding_dim=16,\n",
    "    hidden_size=32,\n",
    "    seq_len=SEQ_LEN,\n",
    "    bidirectional=False\n",
    ")\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================\n",
      "Layer                 Kernel         Output       Params          FLOPs\n",
      "=======================================================================\n",
      "0_embedding         [16, 24927]   [32, 154, 16]   398,832         4,928\n",
      "1_gru                         -   [32, 154, 32]     4,800   200,273,920\n",
      "2_linear.Linear_0   [4928, 128]       [32, 128]   630,912    40,366,080\n",
      "3_linear.Tanh_1               -       [32, 128]         0        20,480\n",
      "4_linear.Linear_2     [128, 32]        [32, 32]     4,128       261,120\n",
      "5_linear.Tanh_3               -        [32, 32]         0         5,120\n",
      "6_linear.Linear_4       [32, 3]         [32, 3]        99         6,048\n",
      "=======================================================================\n",
      "Total params: 1,038,771\n",
      "Trainable params: 1,038,771\n",
      "Non-trainable params: 0\n",
      "Total FLOPs: 240,937,696 / 240.94 MFLOPs\n",
      "-----------------------------------------------------------------------\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 1.88\n",
      "Params size (MB): 3.96\n",
      "Estimated Total Size (MB): 5.88\n",
      "=======================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchutils as tu\n",
    "\n",
    "class GRUnet(nn.Module):\n",
    "    def __init__(self, rnn_conf = config) -> None:\n",
    "        super().__init__()\n",
    "        self.rnn_conf = rnn_conf\n",
    "        self.seq_len    = rnn_conf.seq_len \n",
    "        self.emb_size   = rnn_conf.embedding_dim \n",
    "        self.hidden_dim = rnn_conf.hidden_size\n",
    "        self.n_layers   = rnn_conf.n_layers\n",
    "        self.vocab_size = rnn_conf.vocab_size\n",
    "        self.bidirectional = bool(rnn_conf.bidirectional)\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.emb_size)\n",
    "\n",
    "        self.bidirect_factor = 2 if self.bidirectional == 1 else 1\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.emb_size,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=self.n_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=self.bidirectional,\n",
    "            # device=rnn_conf.device\n",
    "            )\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim*self.seq_len*self.bidirect_factor, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128,32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32,3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x.to(self.rnn_conf.device)) # Пернесим данные на девайс и создаем ембеддинги\n",
    "        output, _ = self.gru(x) # Забираем hidden states со всех промежуточных состояний, второй выход финального слоя отправляем в _\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        out = self.linear(output.squeeze())\n",
    "        return out\n",
    "\n",
    "model_gru = GRUnet(config)\n",
    "model_gru.to(DEVICE)\n",
    "tu.get_model_summary(model_gru, sample_x.to(config.device))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchmetrics.classification import MulticlassAccuracy\n",
    "from torchmetrics.classification import F1Score\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_gru.parameters())\n",
    "metric = F1Score(task=\"multiclass\", num_classes=3, average='macro').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.train_rnn import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss : 0.6316 val_loss : 0.5356\n",
      "train_accuracy : 0.39 val_accuracy : 0.50\n",
      "==================================================\n",
      "Epoch 2\n",
      "train_loss : 0.4686 val_loss : 0.5131\n",
      "train_accuracy : 0.56 val_accuracy : 0.56\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, train_metric, val_metric, rnn_time = train(\n",
    "    epochs=2, \n",
    "    model=model_gru, \n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    optimizer=optimizer,\n",
    "    rnn_conf=config,\n",
    "    criterion=criterion,\n",
    "    metric=metric\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "with open('models_f1_scores.json', 'r') as f:\n",
    "    scores = json.load(f)\n",
    "\n",
    "with open('models_f1_scores.json', 'w') as f:\n",
    "    scores['GRU'] = val_metric[-1]\n",
    "    json.dump(scores,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "\n",
    "torch.save(model_gru, 'model_gru.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.util_func import predict_gru\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Как же уныло… Я вынужден констатировать, что славная студия Дисней утратила моё доверие и попала в чёрный список студий, новые мультфильмы которых теперь я смотреть не буду. Признаться, в списке до этого были лишь ДримВоркс, но если учесть, что для меня в анимации существует только три крупных рыбы — Дисней, ДримВоркс и Пиксар, то надежда остаётся только на последних. Те, слава Богу, в последние годы делают исключительно шедевры или близко к ним, так что можно не беспокоиться. \n",
      "\n",
      "Ближе к «Рапунцель». Во время просмотра у меня постоянно копились новые претензии, которые я впоследствии забывал по причине их обильности. Поэтому я пойду проверенной схемой, поочередно обозвав плохими словами сюжет, юмор и персонажей. Начнём.\n",
      "\n",
      "I. Сюжет.\n",
      "\n",
      "Герои движутся из точки А в точку Б, попутно зарабатывая приключения на свою пятую точку. У меня сразу возникает дежавю, потому что тоже самое я писал в своём отзыве на «Ледниковый период». Ну мультфильмов с такой концепцией — миллионы. Другое дело, что я такие мультики не люблю. Единственный плюс, который я нашёл — нет говорящих животных. Ну и обязательная любовная линия. Как же без этого. Всё по законам тупых, банальных фильмов. Про это писать не буду, ибо и так понятно.\n",
      "\n",
      "Чем заканчивается мультик, понятно тоже. Вроде бы неожиданные сюжетные твисты порой оборачиваются таким абсурдом…\n",
      "\n",
      "PS. В одной рецензии прочитал, что сюжет в мультфильме гениальный. Жуть.\n",
      "\n",
      "II. Персонажи.\n",
      "\n",
      "С ними вообще беда. Главный мужик (тот, что вор) карикатурен до жути — самодовольный, конечно, красавчик, но внутри он лапочка. Рапунцель — тоже красотка, как и подобает, и характер замечательный — сказка же, поэтому хорошие персонажи должны быть просто феноменально хорошими. Конь напоминает осла из Шрека, только лучше — молчит всё время. Стражники, естественно, тупые, а мачеха умная, но очень злая. Штамп на штампе, поэтому и скучно. \n",
      "\n",
      "III. Юмор.\n",
      "\n",
      "А вот и самая в пух и прах разносимая мною категория. Приступаю к разгрому со зловещим смехом.\n",
      "\n",
      "Одна из главных проблем современных мультфильмов — это то, что их всех шлифуют под целевую аудиторию, то есть под детсад и началку. Ни одной более менее нормальной шутки я вспомнить не могу, потому что весь юмор заключается в ударах сковородкой по голове и тому подобные вещи. Я искренне не понимаю, почему это так смешно. Мультипликаторам давно пора прекратить вставлять такие вещи в мультфильмы, ведь это развивает жестокость в детях! Сейчас под понятием «кино для всей семьи» понимаются комедии вроде «Один дома» с пытками, в прямом смысле слова. Я уверен, что боссы студий это прекрасно понимают, но им нужны лишь деньги. По-настоящему добрые мультфильмы не начнут делать до тех пор, пока есть спрос на такие поделки. Очевидно, что спрос на такую продукцию будет всегда, поэтому ничего поделать уже нельзя. Я расстроен. Мне противно слышать, как после ударов по голове чугунной сковородой зал взрывается от детского смеха.\n",
      "\n",
      "Заканчиваю разгром с грустными мыслями. Я ненавижу мультфильм «Том и Джерри».\n",
      "\n",
      "Бонус:\n",
      "\n",
      "IV. Мъюзикальная составляющая.\n",
      "\n",
      "Мне абсолютно наплевать, какое качество у песен, а всё потому, что я не переношу этот жанр. Помню, как в своей рецензии на «Король лев» я ругал Дисней за лишнюю трату экранного времени. А ругать жанр следует не только за это. Вот представьте ситуацию: заходите вы в автобус, передаёте деньги за проезд, после чего кондуктор нараспев говорит «Спасибо»; вы, также напевая, отвечаете «Пожалуйста», и все пассажиры начинают танцевать и петь. Абсурд? Абсурд. Поэтому я и не люблю мюзиклы. \n",
      "\n",
      "Ну а для любителей — песни вроде хорошие, качественные. Правда, весь смысл, наверное, теряется при переводе, так что при возможности смотрите в оригинале с субтитрами.\n",
      "\n",
      "Вот и всё. Если можно, подведу итоги года. \n",
      "\n",
      "История игрушек 3 — 9,5 из 10.\n",
      "\n",
      "Легенды ночных стражей — 5,5 из 10.\n",
      "\n",
      "Как приручить дракона — 4 из 10.\n",
      "\n",
      "Запутанная история — 4 из 10\n",
      "\n",
      "Пиксар, как обычно, лучшие, а Дисней — неожиданно также плохи, как и Дримы. \n",
      "\n",
      "Не ходите на этот мультик.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Bad', 0.04)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df.query('label == 0')['content'].values[0]\n",
    "print(text)\n",
    "\n",
    "predict_gru(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['part', 'movie_name', 'review_id', 'author', 'date', 'title', 'grade3',\n",
      "       'grade10', 'content'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade3</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>\\n\"Блеф» — одна из моих самых любимых комедий....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>\\nАдриано Челентано продолжает радовать нас св...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>\\nНесомненно, это один из великих фильмов 80-х...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>\\nЭта фраза на мой взгляд отражает сюжет несом...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>\\n- как пела Земфира, скорее всего, по соверше...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    grade3                                            content  label\n",
       "0     Good  \\n\"Блеф» — одна из моих самых любимых комедий....      2\n",
       "1     Good  \\nАдриано Челентано продолжает радовать нас св...      2\n",
       "2     Good  \\nНесомненно, это один из великих фильмов 80-х...      2\n",
       "3     Good  \\nЭта фраза на мой взгляд отражает сюжет несом...      2\n",
       "4  Neutral  \\n- как пела Земфира, скорее всего, по соверше...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем датасет и выбиарем колнки с отзывом и оценкой\n",
    "df = pd.read_json('../kinopoisk.jsonl', lines=True)\n",
    "print(df.columns)\n",
    "df = df[['grade3', 'content']]\n",
    "# df.head()\n",
    "# Encode label\n",
    "df['label'] = df[\"grade3\"].apply(encode)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# импортируем трансформеры\n",
    "import transformers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistilBERT:\n",
    "\n",
    "## задаем саму модель\n",
    "model_class = transformers.DistilBertModel\n",
    "\n",
    "# токенайзер к ней (для некоторых моделей токенайзер будет отличаться, см.\n",
    "## в документации к каждой модели конкретно)\n",
    "tokenizer_class = transformers.DistilBertTokenizer\n",
    "\n",
    "## WordPiece\n",
    "## BPE - Byte pair encoding\n",
    "\n",
    "## загружаем веса для моделей\n",
    "pretrained_weights = 'distilbert-base-uncased' # tiny -> base-> large -> XL\n",
    "\n",
    "###########################################\n",
    "# создаем объекты токенизатора для и модели\n",
    "tokenizer = tokenizer_class.from_pretrained('distilbert-base-uncased')\n",
    "model = model_class.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## зададим максимальную длину последовательности\n",
    "MAX_LEN = 154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7632, 2338, 2143, 10608, 102]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# токенизируем одну фразу\n",
    "tokenizer.encode(\n",
    "    'Hi book film monkey',\n",
    "    add_special_tokens=True,\n",
    "    truncation=True,\n",
    "    max_length=MAX_LEN,\n",
    "    # padding='max_length'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [101, 1000, 1181, 29436, 15290, 29749, 1090, 1...\n",
       "1        [101, 1180, 29742, 16856, 10325, 28995, 14150,...\n",
       "2        [101, 1192, 15290, 29747, 14150, 29745, 18947,...\n",
       "3        [101, 1208, 22919, 10260, 1199, 16856, 10260, ...\n",
       "4        [101, 1011, 1189, 10260, 23925, 1194, 15290, 2...\n",
       "                               ...                        \n",
       "36586    [101, 1192, 29748, 1196, 1202, 15290, 29741, 1...\n",
       "36587    [101, 1191, 14150, 29743, 18947, 14150, 1192, ...\n",
       "36588    [101, 1199, 10325, 29436, 23742, 29745, 1194, ...\n",
       "36589    [101, 2385, 1196, 15290, 18947, 22919, 17432, ...\n",
       "36590    [101, 1208, 29750, 1010, 1189, 10260, 23925, 1...\n",
       "Name: content, Length: 36591, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# применяем токенизатор:\n",
    "# -≥ add_special_tokens = добавляем служебные токены (CLS=101, SEP=102)\n",
    "# -≥ truncation = обрезаем по максимальной длине\n",
    "# -≥ max_length = максимальная длина последовательности\n",
    "tokenized = df['content'].apply((lambda x: tokenizer.encode(x,\n",
    "                                                                      add_special_tokens=True,\n",
    "                                                                      truncation=True,\n",
    "                                                                      max_length=MAX_LEN)))\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы дополнить последовательности до фиксированной длины, допишем нули к\n",
    "# коротким последовательностям\n",
    "padded = np.array([i + [0]*(MAX_LEN-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# чтобы attention не считался для позиций, где установлены фиктивные\n",
    "# нулевые токены, мы делаем для него маску\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36591, 154)\n",
      "(36591, 154)\n"
     ]
    }
   ],
   "source": [
    "print(padded.shape); print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertInputs(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_inputs, attention_masks):\n",
    "        super().__init__()\n",
    "        self.tokenized_inputs = tokenized_inputs\n",
    "        self.attention_masks = attention_masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tokenized_inputs.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ids = self.tokenized_inputs[idx]\n",
    "        ams = self.attention_masks[idx]\n",
    "\n",
    "        return ids, ams\n",
    "\n",
    "dataset = BertInputs(padded, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 154]) torch.Size([10, 154])\n"
     ]
    }
   ],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=False)\n",
    "sample_ids, sample_ams = next(iter(loader))\n",
    "print(sample_ids.shape, sample_ams.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1000,  1181,  ..., 29754, 10325,   102],\n",
       "        [  101,  1180, 29742,  ..., 10325, 15290,   102],\n",
       "        [  101,  1192, 15290,  ..., 22919, 16856,   102],\n",
       "        ...,\n",
       "        [  101,  1199, 10325,  ..., 29113, 29744,   102],\n",
       "        [  101,  1182, 15290,  ..., 10325, 29747,   102],\n",
       "        [  101,  1192, 10260,  ...,  1194, 16856,   102]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 38s, sys: 1.93 s, total: 4min 40s\n",
      "Wall time: 4min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36591"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "features = []\n",
    "for inputs, attention_masks in loader:\n",
    "# Получаем выход модели (нам оттуда нужно не все)\n",
    "    with torch.inference_mode():\n",
    "        last_hidden_states = model(inputs.cuda(), attention_mask=attention_masks.cuda())\n",
    "        vectors = last_hidden_states[0][:,0,:].cpu().numpy()\n",
    "    features.extend(vectors)\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: 27443, Target shape: 27443\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(features, df['label'], stratify=df['label'])\n",
    "print(f'Features shape: {len(X_train)}, Target shape: {len(y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    74.510125\n",
       "0    12.984067\n",
       "1    12.505807\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()/len(features)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Создание экземпляра RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "# Применение уменьшения выборки к данным\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3432, 1: 3432, 2: 3432})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4490599038041102\n",
      "f1: 0.35641602474323064\n",
      "Counter({2: 3936, 0: 2956, 1: 2256})\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_resampled, y_resampled)\n",
    "\n",
    "# Оценка классификатора\n",
    "predictions = clf.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, predictions))\n",
    "print(\"f1:\", f1_score(y_val, predictions, average='macro'))\n",
    "print(Counter(predictions))\n",
    "f1_sc = f1_score(y_val, predictions, average='macro')\n",
    "\n",
    "\n",
    "# Save model\n",
    "joblib.dump(clf, 'LogReg_Bert.pkl')\n",
    "\n",
    "# Save f1-score\n",
    "with open('models_f1_scores.json', 'r') as f:\n",
    "    scores = json.load(f)\n",
    "\n",
    "with open('models_f1_scores.json', 'w') as f:\n",
    "    scores['LogReg_Bert'] = f1_sc\n",
    "    json.dump(scores,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test predict\n",
    "\n",
    "## задаем саму модель\n",
    "model_class = transformers.DistilBertModel\n",
    "# токенайзер к ней (для некоторых моделей токенайзер будет отличаться, см.\n",
    "## в документации к каждой модели конкретно)\n",
    "tokenizer_class = transformers.DistilBertTokenizer\n",
    "## загружаем веса для моделей\n",
    "pretrained_weights = 'distilbert-base-uncased' # tiny -> base-> large -> XL\n",
    "# создаем объекты токенизатора для и модели\n",
    "tokenizer = tokenizer_class.from_pretrained('distilbert-base-uncased')\n",
    "model = model_class.from_pretrained('distilbert-base-uncased')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# применяем токенизатор:\n",
    "text = 'фильм просто противно смотреть'\n",
    "tokenized = tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=MAX_LEN)\n",
    "tokenized\n",
    "\n",
    "# чтобы дополнить последовательности до фиксированной длины, допишем нули к\n",
    "# коротким последовательностям\n",
    "padded = np.array(tokenized + [0]*(MAX_LEN-len(tokenized)))\n",
    "\n",
    "# чтобы attention не считался для позиций, где установлены фиктивные\n",
    "# нулевые токены, мы делаем для него маску\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask\n",
    "\n",
    "\n",
    "# # Функция предсказания BERT модели\n",
    "# def prefict_bert(text:str, model)-> str:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Neutral', 0.13)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1199, 10325, 29436, 23742, 29745,  1194, 16856, 14150, 29747,\n",
       "         22919, 14150,  1194, 16856, 14150, 22919, 10325, 25529, 18947, 14150,\n",
       "          1196, 29745, 14150, 22919, 16856, 15290, 22919, 23742,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = torch.LongTensor(attention_mask).unsqueeze(0)\n",
    "padded = torch.LongTensor(padded).unsqueeze(0)\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "features = []\n",
    "with torch.inference_mode():\n",
    "        last_hidden_states = model(padded, attention_mask=attention_mask)\n",
    "        vectors = last_hidden_states[0][:,0,:].numpy()\n",
    "        features = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.44874671e-01,  8.14346671e-02, -1.12671301e-01, -3.86535257e-01,\n",
       "       -5.81587590e-02, -2.34020427e-02,  2.35774994e-01,  2.28222519e-01,\n",
       "       -2.53098249e-01, -2.65456676e-01, -4.38449271e-02, -8.84315893e-02,\n",
       "       -2.86098212e-01,  9.54462737e-02, -1.83469206e-01,  1.70412958e-01,\n",
       "       -6.58771768e-02,  4.89517413e-02,  1.93631589e-01, -8.58901739e-02,\n",
       "       -1.40272990e-01, -1.66548774e-01,  1.23467213e-02, -1.00629516e-02,\n",
       "       -4.32168782e-01, -4.55683246e-02, -1.98923528e-01,  2.45535910e-01,\n",
       "        5.93585931e-02,  1.74247876e-01, -5.27213700e-02,  1.95643976e-01,\n",
       "       -9.63049456e-02,  1.83278620e-01,  1.33451283e-01,  2.17306092e-01,\n",
       "        1.07032582e-01, -1.11143313e-01,  1.52468815e-01, -1.51353434e-01,\n",
       "        1.30054178e-02,  2.32798025e-01, -2.25140303e-01, -3.47766548e-01,\n",
       "        2.22917303e-01, -3.11797053e-01, -2.47316766e+00,  3.62427860e-01,\n",
       "       -3.53537947e-01, -4.43214148e-01,  3.35174590e-01,  5.95794898e-03,\n",
       "        1.73638463e-01, -1.21183336e-01, -9.32048336e-02,  3.80585372e-01,\n",
       "       -9.84501839e-02,  4.06643778e-01,  4.38819602e-02,  2.55377948e-01,\n",
       "        5.23639284e-02,  3.86012375e-01,  7.89083838e-02,  8.04843847e-03,\n",
       "        2.49562129e-01,  1.31783471e-01, -3.47372472e-01,  3.97182494e-01,\n",
       "       -3.05639565e-01,  1.67593077e-01, -5.64467132e-01, -1.02990925e-01,\n",
       "        3.13006073e-01, -3.10286973e-02,  1.45438522e-01,  1.64088249e-01,\n",
       "       -1.23207785e-01,  3.45473677e-01, -2.02864841e-01,  3.38404775e-01,\n",
       "        3.79774928e-01,  1.56726122e-01, -5.20471297e-02,  1.66431665e-01,\n",
       "        6.24619536e-02,  3.08250725e-01, -1.90194473e-01, -1.25783685e-04,\n",
       "       -5.30862398e-02,  5.41830659e-01, -1.23336785e-01, -1.27020836e-01,\n",
       "       -4.93410341e-02,  3.92507821e-01,  3.05239886e-01,  1.20657474e-01,\n",
       "       -3.27985942e-01,  1.74910367e-01,  2.70135731e-01,  1.11653179e-01,\n",
       "        9.03900191e-02,  1.11338355e-01,  3.26170295e-01, -2.91917890e-01,\n",
       "        1.64685279e-01, -5.53466201e-01, -2.63966054e-01, -7.77659332e-03,\n",
       "        2.98770845e-01, -2.23272061e+00,  4.02269885e-02,  1.95897549e-01,\n",
       "       -2.58492947e-01, -4.95033503e-01,  3.20727915e-01,  3.69885385e-01,\n",
       "       -1.36843799e-02, -1.89806402e-01,  1.33689895e-01,  1.15010403e-01,\n",
       "        7.80885592e-02,  5.26439734e-02, -8.00165161e-02, -1.03287935e-01,\n",
       "       -1.92485154e-01,  2.52867520e-01,  1.61605537e-01, -1.70743391e-01,\n",
       "       -1.55652627e-01,  4.56340849e-01, -9.31407958e-02,  5.91353059e-01,\n",
       "       -1.82568029e-01,  1.06561361e-02, -2.56839097e-01,  3.69052708e-01,\n",
       "        3.00922126e-01,  2.07171351e-01, -3.69041830e-01,  3.15229535e-01,\n",
       "       -2.05946907e-01,  3.49006861e-01, -2.56445074e+00,  1.72335431e-01,\n",
       "        6.43638015e-01, -7.30467513e-02,  7.31346160e-02,  9.38274413e-02,\n",
       "        6.27280325e-02, -5.04327901e-02,  1.79432869e-01, -2.05459088e-01,\n",
       "       -9.22690853e-02,  2.30599910e-01, -3.02104622e-01,  8.50189328e-02,\n",
       "        8.68044272e-02,  1.41663432e-01,  4.78658050e-01,  2.24465221e-01,\n",
       "        2.19662517e-01, -6.30031750e-02,  9.54253748e-02,  5.58610894e-02,\n",
       "       -6.34745881e-02, -1.20720170e-01,  2.33745754e-01,  2.65067458e-01,\n",
       "       -2.69058436e-01,  9.35988948e-02,  6.34995028e-02, -6.31647334e-02,\n",
       "        3.59053701e-01,  2.71240771e-01,  4.13181007e-01, -5.64128868e-02,\n",
       "        1.66693985e-01,  4.78442252e-01, -1.03992879e-01, -6.14193752e-02,\n",
       "       -2.78303444e-01,  5.75436234e-01, -5.12254983e-02,  3.98890488e-02,\n",
       "        9.57275406e-02, -3.60204354e-02,  2.17811704e-01, -5.57384174e-03,\n",
       "        1.15429282e-01,  2.19976917e-01, -6.11054339e-02, -2.17842489e-01,\n",
       "       -3.11637133e-01, -3.96995246e-02,  1.88632712e-01,  2.75496393e-01,\n",
       "       -4.06066552e-02, -5.02389967e-01,  2.77187172e-02, -2.35136971e-02,\n",
       "       -2.97932476e-01,  1.03445470e-01, -5.12764528e-02,  2.79105008e-01,\n",
       "        2.39146590e-01,  3.33516502e+00, -1.26927838e-01,  6.56371564e-02,\n",
       "        3.89420599e-01,  2.72787154e-01, -3.34583282e-01, -3.46922964e-01,\n",
       "        4.20470089e-01, -8.06483030e-02,  2.36092672e-01, -2.07910150e-01,\n",
       "        3.49096149e-01, -1.40003145e-01, -1.00915402e-01,  2.76056945e-01,\n",
       "        1.40215322e-01,  7.79556483e-02, -5.83505025e-03,  2.30803400e-01,\n",
       "       -1.79306716e-01, -3.16440798e-02,  7.90646598e-02,  3.07349533e-01,\n",
       "        1.19178705e-01, -1.22810638e+00,  5.17016575e-02, -2.74568379e-01,\n",
       "        1.94911093e-01,  1.65640682e-01, -7.29475439e-01, -3.11020225e-01,\n",
       "       -1.94774121e-01, -3.67647141e-01,  3.78115736e-02,  1.72365665e-01,\n",
       "       -2.43233547e-01, -6.61230311e-02,  5.21538913e-01,  2.40613490e-01,\n",
       "       -2.40173772e-01, -1.15994416e-01,  2.13434085e-01, -8.90353173e-02,\n",
       "        8.55333209e-02, -3.18476379e-01,  1.24332033e-01, -4.60819066e-01,\n",
       "       -2.00754642e-01, -1.23727225e-01, -2.46155620e-01, -6.81506246e-02,\n",
       "        8.71084332e-02, -7.05688372e-02, -4.39100295e-01, -5.36459498e-02,\n",
       "       -3.50696445e-02, -1.09905256e-02,  6.74341321e-02,  1.09820023e-01,\n",
       "       -7.06500858e-02,  8.24787989e-02,  2.48570651e-01, -3.24536264e-01,\n",
       "        2.44736254e-01, -2.91402340e-01, -1.71029419e-01,  4.46231477e-02,\n",
       "       -3.82817566e-01, -2.98334265e+00,  8.85391459e-02, -1.79829866e-01,\n",
       "        4.65013802e-01,  4.27515745e-01, -3.78229350e-01,  6.26293942e-02,\n",
       "        1.05024263e-01,  2.98301399e-01, -2.17339173e-01,  1.37709931e-01,\n",
       "        2.15688303e-01,  1.93057135e-01, -3.49520706e-02, -3.92871022e-01,\n",
       "        2.81142354e-01, -9.01429206e-02, -1.71525329e-01,  1.71891063e-01,\n",
       "        1.88578904e-01,  1.00521393e-01, -1.18871465e-01, -1.38775702e-03,\n",
       "        3.13508749e-01,  4.36803140e-02,  2.41114050e-01, -1.89296287e-02,\n",
       "       -8.39481577e-02, -1.90400600e-01,  2.56768554e-01, -1.47465512e-01,\n",
       "       -4.74639952e-01,  1.82195410e-01, -8.91890079e-02, -1.29657984e-01,\n",
       "       -3.15429115e+00,  1.90461561e-01, -2.21783444e-01, -1.82537198e-01,\n",
       "        1.45349756e-01, -3.29964042e-01,  4.71714646e-01, -2.88517654e-01,\n",
       "       -9.68258306e-02, -1.84976026e-01, -5.74601553e-02,  1.15595981e-01,\n",
       "       -8.25292841e-02,  2.77016126e-02,  2.54959077e-01, -2.32117385e-01,\n",
       "        5.47312975e-01,  6.97647184e-02,  3.01332250e-02, -2.19251752e-01,\n",
       "        7.57926479e-02, -1.50406882e-01, -1.42446041e-01,  9.18893591e-02,\n",
       "        2.57900923e-01,  3.62348467e-01, -2.85911411e-01, -2.81562358e-01,\n",
       "       -2.77537704e-01, -4.86504942e-01, -1.70669004e-01, -5.47590494e-01,\n",
       "       -8.20690766e-02,  7.00265467e-02,  1.93933532e-01, -1.25179484e-01,\n",
       "       -1.14052901e-02,  3.61673594e-01,  4.34141546e-01, -7.92248547e-02,\n",
       "        1.40999258e-01,  4.65152025e-01,  2.26740390e-01,  9.17385891e-02,\n",
       "        5.81242263e-01,  4.89756046e-03,  1.98221549e-01, -2.62246877e-02,\n",
       "       -2.29669169e-01,  1.49959415e-01,  1.64611131e-01,  5.31155877e-02,\n",
       "        1.10365641e+00, -2.28625238e-01,  2.23567188e-01, -2.31096342e-01,\n",
       "        2.83993334e-01, -9.71994102e-02, -2.09786043e-01,  1.41149655e-01,\n",
       "        3.51009220e-01,  1.86752472e-02, -2.47713532e-02, -3.17825675e-01,\n",
       "        1.06465481e-01, -2.91191399e-01,  4.04417142e-02, -5.60684204e-01,\n",
       "        7.61385337e-02, -3.39815468e-02, -2.59663939e-01,  5.48122048e-01,\n",
       "       -6.31445572e-02, -9.21325982e-01, -3.12613785e-01,  2.38234788e-01,\n",
       "       -3.12403679e-01, -1.14989161e-01,  1.52472749e-01, -1.68416556e-02,\n",
       "       -3.70752364e-01, -9.46043953e-02, -1.15972489e-01,  3.58188540e-01,\n",
       "       -1.74795955e-01,  1.08324446e-01, -1.09328412e-01,  3.01294804e-01,\n",
       "       -6.91020966e-01,  1.85055882e-01,  2.35041186e-01,  2.39654392e-01,\n",
       "        3.06502789e-01,  2.04316646e-01, -4.00204539e-01,  1.68791994e-01,\n",
       "        3.54572117e-01, -5.84522545e-01,  1.88317835e-01, -1.24969386e-01,\n",
       "        6.64446577e-02, -3.12751770e-01, -2.13521451e-01, -6.44524917e-02,\n",
       "        1.52252913e-01, -3.66156787e-01, -2.19642505e-01,  1.07284799e-01,\n",
       "        3.18409443e-01,  6.60248995e-02, -8.53395537e-02,  1.37083709e-01,\n",
       "        1.55056253e-01,  1.51683196e-01,  7.62897909e-01, -4.73723225e-02,\n",
       "       -9.06145647e-02,  3.41856658e-01, -2.15320781e-01,  3.42125595e-01,\n",
       "       -8.36522132e-03, -7.19257966e-02, -4.25916970e-01, -8.64392146e-03,\n",
       "        1.39515623e-01,  2.27411315e-01,  9.88237094e-04, -2.48756856e-01,\n",
       "       -2.39507109e-01, -5.57379089e-02,  2.52816707e-01, -1.48307964e-01,\n",
       "       -2.78558899e-02, -7.22421825e-01,  2.74954783e-03, -3.04844677e-02,\n",
       "       -3.36301953e-01,  1.36625275e-01,  4.74013716e-01,  1.15122907e-01,\n",
       "        4.09604371e-01, -9.31152850e-02, -2.29793824e-02,  3.88218880e-01,\n",
       "       -6.00434467e-02,  2.40209311e-01,  8.59132409e-02,  2.92786896e-01,\n",
       "       -6.42877519e-02,  5.93218148e-01,  7.44959246e-03, -2.62433380e-01,\n",
       "       -1.76767215e-01, -4.12965775e-01,  3.40164870e-01,  2.64263600e-01,\n",
       "       -9.38198790e-02, -4.12663281e-01,  7.62692168e-02,  1.37906894e-01,\n",
       "        5.75327314e-02,  3.55810672e-01, -1.37817860e+00,  1.68032601e-01,\n",
       "        2.76393831e-01, -2.87954599e-01,  4.41732630e-02, -6.29137978e-02,\n",
       "        5.90006402e-03,  1.86394662e-01,  1.13331102e-01,  1.99469462e-01,\n",
       "       -5.87220609e-01, -3.53873260e-02,  5.79982214e-02, -7.25818216e-04,\n",
       "        1.07190438e-01,  3.02569922e-02,  1.42801195e-01, -5.98775744e-02,\n",
       "        8.73393491e-02,  1.85550317e-01, -1.16050847e-01,  5.72531283e-01,\n",
       "        1.99445263e-01, -2.52602220e-01, -1.09121524e-01, -2.09255710e-01,\n",
       "       -3.17618027e-02,  1.93596154e-01, -1.31529763e-01,  1.74882889e-01,\n",
       "        2.82368809e-01, -1.03286839e+00, -3.60122204e-01, -4.83390279e-02,\n",
       "        2.07017407e-01,  2.39783838e-01,  4.47824001e-02,  3.29800427e-01,\n",
       "        2.25539178e-01,  4.28983808e-01, -8.39611590e-02,  1.88028634e-01,\n",
       "        1.87306285e-01, -7.82120451e-02,  3.59784305e-01,  1.69795632e-01,\n",
       "       -2.44368628e-01, -1.60260648e-01,  1.04475059e-01, -3.28439087e-01,\n",
       "       -4.60418850e-01,  1.94983214e-01, -6.38453197e-03, -4.28535268e-02,\n",
       "        6.03595637e-02,  8.05354491e-02, -3.98641318e-01,  2.69062985e-02,\n",
       "       -2.36444235e-01, -1.66353166e-01,  1.74870163e-01, -2.59019166e-01,\n",
       "       -1.38749480e-01, -7.84870088e-02, -5.29552877e-01, -6.14794075e-01,\n",
       "       -1.60827920e-01, -1.28606200e-01, -2.86466279e-03,  1.32273480e-01,\n",
       "        9.59336311e-02,  6.68421015e-03, -1.69462174e-01,  2.30290517e-01,\n",
       "       -6.34832263e-01, -9.86565351e-02,  1.06779113e-01,  4.82769787e-01,\n",
       "       -1.20226696e-01, -1.71102971e-01,  6.85292184e-02, -3.73464435e-01,\n",
       "       -1.24121912e-01,  2.59628803e-01,  4.13737744e-02,  1.98581696e-01,\n",
       "        4.34438959e-02,  2.27367178e-01,  2.23070569e-02,  2.05877274e-02,\n",
       "       -2.91801780e-01, -2.73467779e-01,  1.18560806e-01,  2.98945531e-02,\n",
       "        2.33627200e-01,  5.29774167e-02,  1.51189566e-01,  2.56598175e-01,\n",
       "       -2.18859449e-01,  2.94746965e-01, -4.47162688e-02,  1.24116868e-01,\n",
       "        2.71205097e-01,  2.28794906e-02, -1.87958971e-01,  1.06873326e-01,\n",
       "        1.58854678e-01,  3.94289829e-02, -6.01620555e-01, -2.08595112e-01,\n",
       "        1.64804250e-01,  2.32786536e-02, -5.99717796e-01,  7.40721598e-02,\n",
       "        1.64141968e-01, -2.19770774e-01, -2.27216989e-01,  4.86183213e-03,\n",
       "        1.86129725e+00,  3.70325297e-01, -2.74692662e-02,  1.65763363e-01,\n",
       "       -2.42902175e-01,  5.85969314e-02, -1.25219226e-01,  1.31730527e-01,\n",
       "       -7.43399560e-02,  1.34173095e-01, -1.46284282e-01,  1.41596630e-01,\n",
       "       -4.07346874e-01,  1.30115390e-01,  2.55651474e-01,  8.81450623e-02,\n",
       "        6.42016251e-03, -2.49408260e-02, -4.98907089e-01,  8.90699700e-02,\n",
       "       -2.51124412e-01,  2.52930939e-01, -4.77354266e-02,  1.91786334e-01,\n",
       "        2.52257675e-01,  4.32919115e-01, -1.37254894e-01, -1.26604065e-01,\n",
       "       -1.08183943e-01,  3.14886957e-01, -9.12946984e-02, -4.32520621e-02,\n",
       "        5.41658811e-02,  2.66293645e-01,  2.32380301e-01, -2.08094105e-01,\n",
       "        8.25942829e-02, -4.42056596e-01, -3.95172566e-01,  1.38562247e-01,\n",
       "        2.39778608e-01, -1.12835951e-01,  1.30281851e-01,  2.25166112e-01,\n",
       "       -6.30132779e-02,  2.12636247e-01, -2.06229344e-01, -4.75588202e-01,\n",
       "        1.09030664e-01,  4.53054070e-01,  9.88067463e-02,  1.74753014e-02,\n",
       "        9.45992470e-02,  1.27925053e-01,  1.82650387e-01,  1.72809120e-02,\n",
       "        7.17537925e-02, -2.76489425e-02, -3.01643703e-02,  4.81652558e-01,\n",
       "       -3.17938551e-02,  2.55511820e-01,  2.07634225e-01,  1.40450001e-01,\n",
       "        1.15683470e-02, -2.21649632e-01, -2.86027670e-01,  1.01034328e-01,\n",
       "       -2.41466030e-01, -3.48562226e-02, -4.29141931e-02,  1.23983338e-01,\n",
       "        2.30988815e-01,  2.90988624e-01, -8.17456245e-02, -8.35076049e-02,\n",
       "        4.32924032e-01, -1.21783167e-01, -1.21303633e-01, -2.37126374e+00,\n",
       "        2.62354285e-01,  3.74017119e-01, -2.16012690e-02, -1.12070933e-01,\n",
       "        3.20615262e-01,  6.05336800e-02, -9.54950005e-02, -3.16990644e-01,\n",
       "       -3.28844152e-02,  7.56565258e-02,  3.02231878e-01,  3.29559803e-01,\n",
       "        2.52635330e-01,  1.49389967e-01,  7.06314296e-02,  1.53027296e-01,\n",
       "       -1.11348368e-01, -5.82260489e-02, -3.10931981e-01, -7.35822245e-02,\n",
       "        1.17833577e-01,  1.19737782e-01, -5.35825007e-02, -5.03589928e-01,\n",
       "        2.22571433e-01, -4.67209332e-02, -1.51751280e-01, -1.37492329e-01,\n",
       "        5.37376642e-01,  1.01312898e-01,  2.23841339e-01, -6.65678759e-04,\n",
       "        2.67437130e-01, -2.10840896e-01, -3.48014444e-01,  8.48843306e-02,\n",
       "       -2.33210430e-01,  8.16835016e-02,  2.90250987e-01,  2.44127996e-02,\n",
       "        5.59060514e-01, -2.07246989e-01,  1.49894744e-01,  1.97983891e-01,\n",
       "        7.56371394e-02,  5.03417477e-02, -3.10916454e-01,  2.93906540e-01,\n",
       "       -1.25582129e-01, -4.50036049e-01,  2.09181588e-02, -1.13704048e-01,\n",
       "        8.84161517e-02,  2.92425662e-01, -3.47347148e-02,  4.72068191e-02,\n",
       "        3.47121693e-02, -3.94441068e-01,  5.07368557e-02, -4.32250828e-01,\n",
       "       -2.57484373e-02, -4.87982988e-01, -3.13892290e-02,  3.22406679e-01,\n",
       "       -1.21503703e-01, -5.60941994e-01,  8.15662742e-02,  1.86643243e-01,\n",
       "       -2.96308637e-01, -3.60748172e-01, -2.69550472e-01,  1.52321830e-01,\n",
       "        2.39902109e-01,  3.25598925e-01,  5.24313301e-02,  5.17407894e-01,\n",
       "        6.12798095e-01,  2.76259243e-01,  1.54962733e-01, -1.58279523e-01,\n",
       "        1.91088185e-01,  9.63738859e-02, -2.67491583e-02,  3.88603777e-01,\n",
       "       -6.47176456e+00, -2.23046854e-01,  1.58590779e-01,  6.66469336e-02,\n",
       "       -3.16251889e-02,  9.95772481e-02,  2.27989376e-01, -4.57149684e-01,\n",
       "        2.36644804e-01, -1.36388436e-01,  3.72412205e-01, -4.95961398e-01,\n",
       "        2.87121851e-02, -2.84645170e-01,  4.65030789e-01,  5.25060773e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = joblib.load(\"LogReg_Bert.pkl\")\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = clf.predict(features)\n",
    "from functions.util_func import decode\n",
    "decode(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Neutral', 0.07)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functions.util_func import predict_bert\n",
    "predict_bert(text = text, BERT_model = model, tokenizer=tokenizer,clf_model=clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
